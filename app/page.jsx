"use client";
import React, { useEffect, useRef, useState } from "react";
import { toast } from "react-toastify";
import "react-toastify/dist/ReactToastify.css";
import { ToastContainer } from "react-toastify";
import { recognizeVoice } from "./services/voiceRecognition";
import {
  getQuestionIdFromGemini,
  checkAnswerFromGemini,
} from "./services/geminiService";
import { questions } from "./data/questions";
import QuestionImage from "./components/QuestionImage";
import RecordButton from "./components/RecordButton";
import { speakArabicText } from "./services/speechUtils";
import {
  showSuccessConfetti,
  showFailureConfetti,
} from "./services/confettiUtils";
import { PuffLoader } from "react-spinners";

const App = () => {
  const [detectedQuestionId, setDetectedQuestionId] = useState(null);
  const [disable, setDisable] = useState(" ");
  const [userAnswer, setUserAnswer] = useState(null);
  const [answerResult, setAnswerResult] = useState(null);
  const [questionResult, setQuestionResult] = useState({
    id: 0,
    src: "",
    question: "",
    questionVoice: "",
    answer: "",
  });

  const [recording, setRecording] = useState(false);
  const [loadingQuestion, setLoadingQuestion] = useState(false);
  const [loadingAnswer, setLoadingAnswer] = useState(false);

  const successSound = useRef(null);
  const failureSound = useRef(null);
  const questionAudio = useRef(null); // ğŸ§ ØµÙˆØª Ø§Ù„Ø³Ø¤Ø§Ù„

  const startRecordingQuestion = async () => {
    setRecording(true);
    setQuestionResult({ id: 0, src: "", question: "", questionVoice: "", answer: "" });
    setUserAnswer("");

    try {
      setLoadingQuestion(true);
      const voiceText = await recognizeVoice();
      const questionId = await getQuestionIdFromGemini(questions, voiceText);
      setDetectedQuestionId(questionId);
      const questionText = questions.find((q) => q.id == questionId);
      setDisable(questionText.answer);
      console.log(questionText);

      setQuestionResult(questionText);
      setLoadingQuestion(false);

      // ØªØ´ØºÙŠÙ„ ØµÙˆØª Ø§Ù„Ø³Ø¤Ø§Ù„
      if (questionAudio.current && questionText.questionVoice) {
        questionAudio.current.src = questionText.questionVoice;
        questionAudio.current.play();
      }
    } catch (error) {
      console.error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„:", error);
      setLoadingQuestion(false);
    }
    setRecording(false);
  };

  const startRecordingAnswer = async () => {
    setRecording(true);
    setUserAnswer("");
    setLoadingAnswer(true);
    try {
      const answerText = await recognizeVoice();
      const question = questions.find((q) => q.id === detectedQuestionId);
      const isCorrect = await checkAnswerFromGemini(question, answerText);
      setUserAnswer(answerText);
      speakArabicText(answerText);

      setAnswerResult(isCorrect);
      setLoadingAnswer(false);
      if (isCorrect === "ØµØ­ÙŠØ­Ø©") {
        toast.success("Ø¥Ø¬Ø§Ø¨Ø© ØµØ­ÙŠØ­Ø©! ğŸ‰");
        if (successSound.current) {
          successSound.current.currentTime = 0;
          successSound.current.play();
        }
        showSuccessConfetti();
      } else {
        toast.error("Ø¥Ø¬Ø§Ø¨Ø© Ø®Ø§Ø·Ø¦Ø©! ğŸ˜");
        if (failureSound.current) {
          failureSound.current.currentTime = 0;
          failureSound.current.play();
        }
        showFailureConfetti();
      }
    } catch (error) {
      setLoadingAnswer(false);
      console.error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„:", error);
    }
    setRecording(false);
  };

  return (
    <>
      <div className={`app-container ${recording ? "recording" : ""}`}>
        <h1>Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©</h1>
        <div className="image-gallery" style={{ minHeight: "350px" }}>
          <div className="img">
            <QuestionImage
              key={questionResult.id}
              src={questionResult.src.length > 10 ? questionResult.src : ""}
              alt={questionResult.question}
              highlighted={detectedQuestionId === questionResult.id}
            />
          </div>
        </div>
        <div className="button-container">
          <RecordButton
            onMouseDown={startRecordingQuestion}
            onMouseUp={() => setRecording(false)}
            text="ğŸ™ï¸ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„"
            active={recording}
          />
          <RecordButton
            onMouseDown={startRecordingAnswer}
            onMouseUp={() => setRecording(false)}
            text="ğŸ¤ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"
            active={recording}
            disabled={disable}
          />
        </div>
        {loadingQuestion ? (
          <p className="status-text">
            <span>
              <PuffLoader
                color="#1a9de6"
                cssOverride={{}}
                loading
                size={30}
                speedMultiplier={3}
              />
            </span>
            ...Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„
          </p>
        ) : (
          <p className="status-text">{questionResult.question}</p>
        )}

        {!loadingAnswer ? (
          userAnswer ? (
            <p>
              Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {userAnswer} - Ø§Ù„Ù†ØªÙŠØ¬Ø©:{" "}
              {answerResult == "ØµØ­ÙŠØ­Ø©" ? "ØµØ­ÙŠØ­Ø©" : "Ø®Ø§Ø·Ø¦Ø©"}
            </p>
          ) : (
            " "
          )
        ) : (
          <p className="status-text">
            <span>
              <PuffLoader
                color="#1a9de6"
                cssOverride={{}}
                loading
                size={30}
                speedMultiplier={3}
              />
            </span>
            Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø¬Ø§Ø¨Ø©
          </p>
        )}
      </div>

      <audio ref={successSound} src={"/assets/Sound/facts.mp3"} preload="auto" />
      <audio ref={failureSound} src={"/assets/Sound/erorr.mp3"} preload="auto" />
      <audio ref={questionAudio} preload="auto" /> {/* Ù…Ø´ØºÙ„ ØµÙˆØª Ø§Ù„Ø³Ø¤Ø§Ù„ */}

      <ToastContainer />
    </>
  );
};

export default App;
